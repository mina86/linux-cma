\chapter{Sposób użycia CMA}\label{sec:cma-usage}

Pomimo, że idea CMA jest stosunkowo prosta, mechanizm ten urósł do
raczej skomplikowanego interfejsu, który integruje się dość głęboko
z~systemem zarządzania pamięci jądra Linuksa.  Pomimo tego, jego
użycie nie jest szczególnie trudne, a~w~wielu przypadkach autor
sterownika, który chciałby korzystać z~CMA nie musi niczego zmieniać
w~swoim kodzie.

\section{Wykorzystanie w~sterownikach}\label{sec:usage-drivers}

CMA integruje się z~interfejsem programowania DMA (DMA API), co
oznacza, że jeżeli CMA jest włączone i~zintegrowane z~daną
architekturą, poprawnie napisany sterownik (tzn.\ taki, który korzysta
z~DMA API) będzie korzystał z~CMA bez konieczności dokonywania
jakichkolwiek zmian.

Tak naprawdę, sterowniki nie powinny odwoływać się bezpośrednio do
funkcji CMA, gdyż są one zbyt nisko poziomowe i~operują na stronach,
gdy tymczasem sterowniki urządzeń są raczej zainteresowane adresami
szyny.\footnote{W~ogólności, adres szyny strony może być inny niż jej
  adres fizyczny i~DMA API zostało zaprojektowane tak, aby brać to pod
  uwagę.}  Co więcej, CMA nie posiada żadnych mechanizmów
gwarantujących spójność pamięci podręcznej -- zadanie to leży
w~kwestii DMA API.

Najprostszym mechanizmem z~tego interfejsu są funkcje
\code|dma_alloc_coherent| i~\code|dma_free_coherent|.  Służą one
odpowiednio do alokacji i~zwalniania buforów DMA, których zawartość
jest zawsze spójna z~tym co widzi procesor\footnote{W~różnych
  architekturach efekt ten jest uzyskiwany w~różny sposób.
  W~architekturze Intel istnieje gwarancja spójność zawartości kości
  RAM oraz pamięci podręcznej procesora, gdy tymczasem architektura
  ARM nie daje takich gwarancji.  Z~tego powodu, w~systemach opartych
  o~Linuksa działających na platformie ARM, bufory alokowane przy
  pomocy \code|dma_alloc_coherent| nie podlegają buforowaniu w~pamięci
  podręcznej procesora.}.  Wydruk \ref{lst:dma-alloc-example} pokazuje
sposób wykorzystania tych dwóch funkcji.  Prosty sterownik, który
można wykorzystać do testowania CMA można znaleźć
w~\cite{patch:cma-test}, a~dokładniejszy opis DMA API w~rozdziale 15
\cite{bib:ldd3}.

\begin{lstlisting}[float=tbhp,caption={Alokacja bufora DMA z~użyciem
      DMA API.},label=lst:dma-alloc-example]
static struct device *my_dev;

void *my_dev_alloc_buffer(unsigned long size_in_bytes, dma_addr_t *dma_addrp)
{
	void *virt_addr;

	virt_addr = dma_alloc_coherent(my_dev, size_in_bytes,
				       dma_addrp, GFP_KERNEL);
	if (!virt_addr)
		dev_err(my_dev, "Unable to allocate %lu-byte DMA %buffer",
			size_in_bytes);
	return virt_addr;
}

void *my_dev_free_buffer(unsigned long size_in_bytes,
			 void *virt_addr, dma_addr_t dma_addr)
{
	dma_free_coherent(my_dev, size_in_bytes, virt_addr, dma_addr);
}
\end{lstlisting}


\section{Integracja z~architekturą procesora}\label{sec:integrate-with-arch}

CMA działa dzięki rezerwowaniu w~trakcie startu systemu pewnego
regionu pamięci (zwanego regionem CMA), który po zainicjowaniu całego
mechanizmu CMA jest zwracany do systemu (tak że może być
wykorzystywany do pewnego rodzaju alokacji).  Aby taki obszar został
zarezerwowany, w~trakcie startu systemu musi zostać wywołana funkcja:

\begin{lstlisting}
void dma_contiguous_reserve(phys_addr_t limit);
\end{lstlisting}

Wywołanie to musi nastąpić gdy podsystem alokacji pamięci czasu startu
systemu (tj.\ {\it. memblock}) zostanie zainicjowany, ale przed
aktywowaniem alokatora stron.  Dla przykładu w~architekturze ARM
dogodnym miejscem jest funkcja \code|arm_memblock_init|, a~x86
-- \code|setup_arch| zaraz po aktywowaniu memblock.

Argument \code|limit| określa górny adres pamięci fizycznej,
którego zarezerwowany obszar CMA nie przekroczy.  Dzięki niemu regiony
CMA mogą zostać ograniczone do adresów dostępnych dla urządzeń
w~systemie.  Przykładowo w~architekturze ARM argument ten przyjmuje
wartość zmiennych \code|arm_dma_limit| lub
\code|arm_lowmem_limit|, którakolwiek jest mniejsza,
a~w~procesorach 64-bitowych może zaistnieć potrzeba ograniczenia do
32-bitowych adresów.  Jeżeli wartością tego argumentu jest zero, na
region CMA nie jest narzucany żaden limit.

Ilość zarezerwowanej pamięci zależy od argumentu \code|cma|
(który określa rozmiar regionu w~bajtach) przekazywanego do jądra
w~trakcie startu, lub, jeżeli argumentu tego nie ma, ustawień
kompilacji jądra.  W~trakcie konfiguracji kompilacji jądra można
wybrać jeden z~czterech sposobów określania rozmiaru:

\begin{enumerate}
\item stały rozmiar wyrażony w~bajtach,
\item rozmiar wyrażony w~procentach całkowitej pamięci dostępnej
  w~systemie,
\item większe z~pierwszych dwóch opcji, lub
\item mniejsze z~pierwszych dwóch opcji.
\end{enumerate}

Domyślną wartością konfiguracji jest alokacja \unit[16]{MiB}.

Funkcja \code|dma_contiguous_reserve| tworzy domyślny region
CMA wykorzystywany przez wszystkie urządzenia, które nie mają
przypisanych prywatnych regionów CMA.  Prywatne regiony CMA opisane są
w~podrozdziale \ref{sec:priv-regions}.


\subsection{Poprawki specyficzne dla architektury}

Na niektórych architekturach może zaistnieć przeprowadzenia dodatkowej
obróbki zarezerwowanych regionów pamięci.

Przykładowo, z~uwagi na brak spójności pamięci RAM i~pamięci
podręcznej procesora na architekturze ARM, wymagane jest aby strony,
z~których korzystają urządzenia, były mapowane jako niepodlegające
buforowaniu (\ang{noncacheable}).  Co więcej, specyfikacja
architektury mówi, że jeżeli dana strona jest mapowana z~różnymi
parametrami buforowania (\ang{cacheability}), efekt działania systemu
nie jest zdefiniowany.

Dlatego w~architekturze ARM, kod integrujący CMA z~DMA API zmienia
mapowanie strony na niechachewalne na czas, gdy jest ona używana przez
urządzenie.

Z~drugiej strony, aby przyśpieszyć translację adresów, jądro stara się
stosować tak zwane wielkie strony.  Pozwala to zmapować \unit[2]{MiB}
pamięci (512 normalnych stron o~rozmiarze \unit[4]{KiB}) poprzez jeden
wpis w~tablicy mapowania.

Niestety, takie mapowanie uniemożliwia zmianę parametrów mapowania
pojedynczej strony.  Z~uwagi na to, regiony CMA są przygotowane w~ten
sposób, że mapowanie wielkich stron jest rozbijane na wiele mapowań
pojedynczych stron co pozwala na (w~miarę) proste modyfikowanie
ustawień cachowania danej strony.  Więcej na ten temat można
przeczytać w~artykule \cite{bib:cma-and-arm}.

Aby to umożliwić, dla każdego regionu CMA, zawołana zostanie funkcja

\begin{lstlisting}
void dma_contiguous_early_fixup(phys_addr_t base, unsigned long size);
\end{lstlisting}

Nie jest ona zdefiniowana przez CMA i~musi zostać dostarczona przez
kod danej architektury.  Jej deklaracja powinna znaleźć się w~pliku
nagłówkowym \code|asm/dma-contiguous.h|.  Jeżeli funkcjonalność
ta nie jest konieczna, wystarczy dostarczyć pustą implementację
(np.\ prezentowaną przez wydruk \ref{lst:empty-fixup}).

\begin{lstlisting}[float=tbhp,caption={Plik nagłówkowy
      \code|asm/dma-contiguous.h| z~pustą implementacją funkcji
      \code|dma_contiguous_early_fixup|.},label=lst:empty-fixup]
#ifndef ASM_DMA_CONTIGUOUS_H
#define ASM_DMA_CONTIGUOUS_H

#ifdef __KERNEL__

#include <linux/types.h>
#include <asm-generic/dma-contiguous.h>

static inline void
dma_contiguous_early_fixup(phys_addr_t base, unsigned long size)
{
	/* nop, no need for early fixups */
}

#endif
#endif
\end{lstlisting}

Należy pamiętać, że funkcja ta jest wołana dość wcześnie w~trakcie
startu systemu, zatem wiele podsystemów może jeszcze nie być
dostępnych, a~w~szczególności funkcja \code|kmalloc| nie będzie
działać.  Co więcej, może ona zostać wywołana kilkakrotnie, dla
różnych regionów CMA, ale nie więcej niż \code|MAX_CMA_AREAS|
razy (domyślnie 8).

\subsection{Integracja z~podsystemem DMA}\label{sec:usage-integrate}

Aby sterowniki mogły korzystać z~CMA poprzez DMA API, CMA musi zostać
dodane do podsystemu DMA danej architektury.  Alokacja bufora CMA
odbywa się poprzez wywołanie funkcji:

\begin{lstlisting}
struct page *dma_alloc_from_contiguous(
	struct device *dev,
	int count,
	unsigned int align);
\end{lstlisting}

Pierwszym argumentem jest urządzenie na rzecz którego odbywa się
alokacja.  Drugim jest \emph{liczba stron} do zaalokowania.

Trzeci argument to wyrównanie alokacji wyrażone w~rzędzie strony, lub
innymi słowy, jeżeli bufor ma być wyrównany do $a$ bajtów, parametr
\code|align| powinien przyjąć wartość $\log_2 a - \log_2
\mathrm{PAGE\_SIZE}$ (lub dla stron o~rozmiarze \unit[4096]{KiB}:
$\log_2 a - 12$).  Jeżeli żadne wyrównanie nie jest wymagane, należy
zwyczajnie przekazać zero -- zmniejszy to również problem
z~fragmentacją.  Warto zauważyć, że na wartość argumentu
\code|align| nałożone jest ograniczenie
\code|CONFIG_CMA_ALIGNMENT|, który jest ustawiane w~trakcie
kompilacji jądra.  Jego domyślną wartością jest osiem (co oznacza
wyrównanie do 256 stron).

Funkcja \code|dma_alloc_from_contiguous| zwraca wskaźnik na
pierwszą stronę spośród serii \code|count| zaalokowanych stron,
lub \code|NULL| w~przypadku nieudanej alokacji.

Do zwolnienia bufora wykorzystywana jest funkcja:

\begin{lstlisting}
bool dma_release_from_contiguous(
	struct device *dev,
	struct page *pages,
	int count);
\end{lstlisting}

Argumenty \code|dev| i \code|count| mają takie samo
znaczenie jak w~funkcji \code|dma_alloc_from_contiguous|,
a~argument \code|pages| jest wartością zwróconą przez tę funkcję.

Jeżeli dany bufor nie był zaalokowany poprzez CMA, funkcja
\code|dma_release_from_contiguous| zwróci \code|false|.
W~przeciwnym wypadku, bufor zostanie zwolniony i~funkcja zwróci
\code|true|.  Ta zwracana wartość może zostać wykorzystana przez
DMA API aby rozróżnić, czy dany bufor jest buforem CMA, czy też nie.

Wydruk \ref{lst:dma-integration} pokazuje fragment patcha, który
integruje CMA z~podsystemem DMA architektury x86.

\begin{lstlisting}[float=tbhp,caption={Integracja CMA z~podsystemem DMA
      architektury x86.},label=lst:dma-integration]
diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
@@ -99,14 +99,18 @@ void *dma_generic_alloc_coherent(
 				 dma_addr_t *dma_addr, gfp_t flag)
 {
	(*{\it [ \ldots ]}*)
 again:
-	page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
+	if (!(flag & GFP_ATOMIC))
+		page = dma_alloc_from_contiguous(dev, count, get_order(size));
+	if (!page)
+		page = alloc_pages_node(dev_to_node(dev), flag, get_order(size));
 	if (!page)
 		return NULL;
@@ -126,6 +130,16 @@ again:
 	return page_address(page);
 }

+void dma_generic_free_coherent(struct device *dev, size_t size, void *vaddr,
+			       dma_addr_t dma_addr)
+{
+	unsigned int count = PAGE_ALIGN(size) >> PAGE_SHIFT;
+	struct page *page = virt_to_page(vaddr);
+
+	if (!dma_release_from_contiguous(dev, page, count))
+		free_pages((unsigned long)vaddr, get_order(size));
+}
+
\end{lstlisting}

\paragraph{Alokacje w~kontekście atomowym} \hspace{0pt} \\

Należy pamiętać, iż funkcja \code|dma_alloc_from_contiguous|
nie może zostać wywołana w~kontekście atomowym (np.\ z~procedury
obsługi przerwania), a~jednocześnie dopuszczalne jest wywołanie
\code|dma_alloc_coherent| z~kontekstu atomowego.  Z~tego
powodu, subsystem DMA musi posiadać inny mechanizm przeznaczony dla
takich alokacji.

Najprostszym rozwiązaniem jest zarezerwowanie pewnego, stosunkowo
niewielkiego, obszaru pamięci, przeznaczonego do alokacji w~kontekście
atomowym.  Istniejące architektury muszą posiadać tego typu
mechanizmy.


\section{Regiony CMA dla poszczególnych urządzeń}\label{sec:priv-regions}

Po dokonaniu zmian opisanych w~powyższym podrozdziale, sterowniki
urządzeń powinny już działać.  Korzystając z~DMA API odwołują się
bowiem do CMA.

Jednak niektóre urządzenia mogą mieć specyficzne wymagania.  Dla
przykładu, wielo-formatowy koder multimedialny (\ang{Multi-format
  codec}, MFC) znajdujący się na platformie S5PV110 wymaga, aby bufory
na różne dane, znajdowały się w~różnych bankach pamięci (co pozwala na
dostęp do danych przez dwa kanały zwiększając tym sposobem
przepustowość pamięci).  Ponadto, zależnie od istniejących na
platformie urządzeń, wskazane może być izolowanie pewnych grup
urządzeń.  Dla przykładu mieszanie alokacji dla stosunkowo małych
tekstur dla koprocesora graficznego z~alokacjami dużych buforów
przeznaczonych dla kamery, może przyczynić się do zwiększenia
fragmentacji regionu CMA.

Funkcja \code|dma_declare_contiguous| tworzy domyślny region
CMA, ale istnieje możliwość przypisania różnych regionów CMA do
poszczególnych urządzeń.  Istnieje mapowanie wiele-do-jednego pomiędzy
strukturą \code|device|, a~regionem CMA.  Oznacza to, że
pojedynczy region CMA może zostać przypisany do danego urządzenia, ale
jeżeli urządzenie ma korzystać z~wielu regionów CMA konieczne jest
stworzenie kilku struktur \code|device|.

\paragraph{Przypisywanie regionu CMA do pojedynczego urządzenia} \hspace{0pt} \\

Aby przypisać region CMA do urządzenia wystarczy wywołać funkcję:

\begin{lstlisting}
int dma_declare_contiguous(
	struct device *dev,
	unsigned long size,
	phys_addr_t base,
	phys_addr_t limit);
\end{lstlisting}

Pierwszy argument to urządzenie do którego region ma być przypisany.
Drugi to \emph{rozmiar w~bajtach}.  Trzeci to adres gdzie region ma
się zaczynać lub zero, jeżeli nie ma to znaczenia.  Ostatni argument,
\code|limit|, ma takie samo znaczenie jak w~przypadku funkcji
\code|dma_contiguous_reserve|.  Dla przykładu, wydruk
\ref{lst:s5p-priv-region} pokazuje fragment patcha dodającego prywatne
regiony do dwóch urządzeń.

Istnieje limit „prywatnych” regionów CMA, konkretnie
\code|CONFIG_CMA_AREAS|, którego domyślna wartość to siedem.
Jeżeli limit ten zostanie przekroczony, funkcja
\code|dma_declare_contiguous| zacznie zwracać
\code|-ENOSPC|.  Jednakże, jeżeli istnieje taka potrzeba, nic nie
stoi na przeszkodzie aby ten limit zwiększyć w~trakcie kompilacji
jądra.

% For some reason, breaklines=true does not work, so I'm breaking the
% line manually...
\begin{lstlisting}[float=tbhp,caption={Przypisanie prywatnych regionów
      CMA do dwóch urządzeń.},label=lst:s5p-priv-region]
diff --git a/arch/arm/plat-s5p/dev-mfc.c b/arch/arm/plat-s5p/dev-mfc.c

 void __init s5p_mfc_reserve_mem(phys_addr_t rbase, unsigned int rsize,
 				phys_addr_t lbase, unsigned int lsize)
 {
	(*{\it [ \ldots ]}*)
+	if (dma_declare_contiguous(&amp;s5p_device_mfc_r.dev, (*{\color{gray} $\hookleftarrow$}*)
(*{\color{gray} $\hookrightarrow$}*)		rsize, rbase, 0))
+		printk(KERN_ERR "Failed to reserve memory for MFC device (*{\color{gray} $\hookleftarrow$}*)
(*{\color{gray} $\hookrightarrow$}*)			(\%u bytes at 0x\%08lx)\n",
+		       rsize, (unsigned long) rbase); (*{\color{gray} $\hookleftarrow$}*)
(*{\color{gray} $\hookrightarrow$}*)	(*{\it [ \ldots ]}*)
+	if (dma_declare_contiguous(&amp;s5p_device_mfc_l.dev, (*{\color{gray} $\hookleftarrow$}*)
(*{\color{gray} $\hookrightarrow$}*)		lsize, lbase, 0))
+		printk(KERN_ERR "Failed to reserve memory for MFC device (*{\color{gray} $\hookleftarrow$}*)
(*{\color{gray} $\hookrightarrow$}*)			(\%u bytes at 0x\%08lx)\n",
+		       rsize, (unsigned long) rbase);
 }
\end{lstlisting}

\paragraph{Przypisywanie jednego regionu CMA do wielu urządzeń} \hspace{0pt} \\

Odrobinę bardziej skomplikowane jest przypisanie tego samego regionu
do kilku urządzeń.  Obecny interfejs CMA nie udostępnia funkcji, która
by na to pozwalała, ale i~tak nie jest to szczególnie trudne do
osiągnięcia.  Wystarczy zastosować metodę opisaną powyżej, aby
przypisać region do jednego urządzenia, a~następnie skopiować ten
region do drugiego urządzenia.  Całą sekwencja powinna zostać wykonana
jako \code|postcore_initcall|.  Poniższy kod pokazuje jak taki
efekt może zostać osiągnięty:

\begin{lstlisting}
static int __init foo_set_up_cma_areas(void) {
	struct cma *cma = dev_get_cma_area(device1);
	dev_set_cma_area(device2, cma);
	return 0;
}
postcore_initcall(foo_set_up_cma_areas);
\end{lstlisting}

\paragraph{Brak domyślnego regionu} \hspace{0pt} \\

Warto zauważyć, że nic nie stoi na przeszkodzie, aby nie tworzyć
domyślnego regionu CMA.  Oczywiście, jeżeli nie zostanie on stworzony,
urządzenia, którym nie zostaną przypisane prywatne regiony nie będą
mogły korzystać z~buforów CMA.
